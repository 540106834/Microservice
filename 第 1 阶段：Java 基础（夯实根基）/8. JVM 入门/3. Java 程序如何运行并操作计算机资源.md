现在我们来到真正的“动起来”的阶段。

如果前面是 **城市建设**，那这一节就是：

> 🚦车开始上路，电开始流动，数据开始奔跑。

很多工程师知道 Java “不能直接操作硬件”，但不知道中间到底发生了什么。其实这里是一条非常清晰的 **控制链**。

先给你一幅真实结构图：

```
Java代码
   ↓
字节码
   ↓
解释器 / JIT
   ↓
JVM运行时
   ↓
系统调用 (syscall)
   ↓
操作系统内核
   ↓
硬件
```

注意一件非常重要的事实：

 **只有内核能碰硬件。**

用户程序全部要排队。

JVM 也不例外。

---

#  一、内存是如何被真正使用的

很多人误以为：

> new = JVM 给内存

其实更准确是：

> JVM 向操作系统“批发”，再向对象“零售”。

---

##  JVM 如何向 OS 要内存？

常见两种：

### ✅ Linux

```
mmap()
brk()
```

### ✅ Windows

```
VirtualAlloc()
```

比如：

```
-Xmx4G
```

JVM 启动时可能直接：

> mmap 4GB 虚拟地址空间。

注意关键词：

##  虚拟

不是立刻占用物理内存！

只有当你真正触碰那一页：

CPU 会触发：

```
Page Fault（缺页中断）
```

OS 才分配物理页。

这叫：

> **按需分配（Demand Paging）**

非常高效。

---

##  栈其实更“贴近CPU”

线程创建时：

OS 会直接给：

```
~1MB 栈空间（默认）
```

连续内存。

好处巨大：

* 指针移动即可分配
* 无锁
* 无GC
* CPU缓存友好

所以方法调用快得像滑冰。

---

#  一个高手认知：JVM 是“二级内存管理者”

结构是：

```
OS 管：
    虚拟内存
    物理页
    swap

JVM 管：
    堆
    新生代
    老年代
    TLAB
```

所以当出现：

```
Java OOM
```

可能有三种情况：

###  JVM 堆满了

###  Metaspace 满了

###  OS 不给内存（容器限制 / cgroup）

很多排障卡在第三个。

---

#  二、CPU 到底是谁在用？

非常多人误解：

> Java线程 = JVM线程

不。

更准确是：

> Java Thread → 映射 → OS Thread

这叫：

##  1:1 线程模型（HotSpot 默认）

创建线程时，本质发生：

```
pthread_create()
```

内核创建调度实体。

---

## CPU 如何选择谁运行？

Linux 用：

> CFS 调度器（Completely Fair Scheduler）

核心思想：

> “让每个线程看起来都公平。”

它维护一棵红黑树记录：

* 谁跑得多
* 谁跑得少

然后选择“最亏”的那个。

---

##  时间片到了会发生什么？

CPU 会强制：

```
上下文切换
```

保存：

* 寄存器
* 程序计数器
* 栈指针

再加载下一个线程。

这一步非常贵。

所以：

> 线程不是越多越好。

很多系统慢，不是CPU不够，而是：

> 切换过多。

---

## 一个反直觉事实：

如果机器：

```
8核
```

最舒服线程数通常是：

```
8 ~ 16
```

不是 200。

---

#  三、文件与网络其实是“内核代劳”

假设你写：

```java
Files.readAllBytes(path);
```

看似简单。

背后路径是：

```
Java
 → JVM native
   → libc
     → syscall(read)
       → 内核
         → 磁盘驱动
```

数据返回路径反向走一遍。

像一条地下物流隧道。

---

##  为什么系统调用昂贵？

因为发生了：

```
用户态 → 内核态切换
```

CPU 要：

* 切权限
* 切栈
* 刷部分缓存

所以现代高性能框架都在努力：

> 减少 syscall 次数。

例如：

### 👉 Netty

### 👉 epoll

### 👉 io_uring

本质都是：

> “别老敲内核的门。”

---

#  一个网络真相（很多人不知道）

传统 IO：

```
read -> 拷贝到内核缓冲
     -> 再拷贝到用户空间
```

两次复制。

而：

## ⭐ Zero-copy

比如：

```
sendfile()
```

数据直接：

```
磁盘 → 内核 → 网卡
```

不经过用户空间。

CPU压力骤降。

这就是为什么：

> Nginx 极强。

---

#  四、解释执行 vs JIT

当字节码第一次执行：

👉 **解释器上场。**

逐条翻译成机器指令。

优点：

* 启动快

缺点：

* 慢。

---

## JVM 很聪明。

它会观察：

> 哪些代码被疯狂调用？

这些叫：

## ⭐ 热点代码（HotSpot名字来源）

然后：

> JIT 编译成本地机器码。

下次直接跑。

速度接近 C。

---

### 更疯狂的是：

JIT 会做：

* 内联
* 锁消除
* 标量替换
* 逃逸分析

有时候甚至：

> 比手写C还快。

因为它：

**知道运行时数据。**

编译器不知道。

---

#  一个架构级顿悟

很多性能问题其实不在 Java。

而在这条链：

```
线程过多 → 调度爆炸
syscall过多 → 内核压力
缺页过多 → 内存抖动
GC频繁 → CPU被抢
```

高手看系统是：

> 整条资源通道。

不是盯某一层。

---

#  给你一幅“资源流动图”

想象一座巨型自动化工厂：

* Java代码 = 控制台指令
* JVM = 中央调度系统
* OS = 总调度室
* CPU = 发动机
* 内存 = 传送带
* 磁盘 = 仓库
* 网卡 = 港口

指令一发出，整座工厂开始协同。

安静，但力量惊人。

---

##  最后给你一个高手分水岭认知

当你看到：

```
CPU 100%
```

不要问：

> Java 怎么了？

先问：

✅ 是用户CPU还是内核CPU？
✅ 是否线程争抢？
✅ 是否大量syscall？
✅ 是否GC？

视野瞬间拉高。

---

如果你愿意继续深入，我强烈推荐下一个理解，它会直接改变你对性能的直觉：

👉 **一次 `new Object()` 到底经历了什么？**
从 TLAB → 指针碰撞 → 内存屏障 → CPU缓存，一路拆开看，会非常震撼。

或者更硬核一点：

👉 **一次系统调用到底慢在哪？CPU里发生了什么？**

选一个，我们继续向更深层潜航。
